#!/usr/local/bin/perl

#
# This script will be developped as a unique flexible
# back-end to the CRS software. Options passed to this
# script will specify ALL of what we need to run a chain,
# many chains, any destinations, with any library version.
#
# This one script may therefore handle multiple production.
#
# Written J.Lauret July 2001.
# Please, follow comments for more information ...
#
#  Some info :
#  The job descriptor should be as follow
#    executable=ThisProgram
#    executableargs=STDOpt,LibraryVersion,Destination,NumEvt,options...
#
#  where
#   ALLOpt         Bit-wise option setup.
#                  Bit 1-2  0 regular (immediate/un-buffered)
#                           1 delayed STD-IO
#                  Bit 3    0 non-optimized
#                           1 optimized
#                  Bit 4-5    enables/disables compressed STDOUT
#                             enables/disables compressed STDERR
#  
#   LibraryVersion can be one of new, dev, old, pro or a version
#                  understood by 'starver'
#   Destination    is a disk-path used for file copy.
#   Numevt         the number of events to process. -1 or 0 means
#                  a large number.
#   Options        as many comma separated options. They will all
#                  go as bfc chain options.
#
# There are 2 cases where the Destination field is used
#
# 1 - In outputstreamtype=HPSS, the file is therefore copied
#     on disk before the CRS software takes care of staging the
#     output onto HPSS.
# 2 - The outputstreamtype=UNIX has been chose __AND__ the
#     stdoutdir was specified as ./ . This will automatically
#     trigger a copy of the local output to the destination.
#

use File::Basename;
use File::Copy;
use Sys::Hostname;

# First of all, turn IO autoflush
$|       = 1;


# Some default hardwired values
$HPSSBASE= "/home/starreco";       # base HPSS path
$NTRIES  = 720;                    # number of tries -1 means infinit tries
$SLPTIME = 120;                    # sleep time in sec between mkpath attempts
$PRGM    = "bfcca";                # this program logical name


# This is for debugging purposes
#foreach $el (keys %ENV){
#   print "$el -> $ENV{$el}\n";
#}
#print "We are now in business ...\n";



# The first element of the argument list
# is rather of unknown usage. It is always
# 0. Afterward, this script accept (in order
# it receives)
shift @ARGV;
$ALLOPT      = shift @ARGV;
$LIBRARY     = shift @ARGV;
$DESTINATION = shift @ARGV;
$NUMEVT      = shift @ARGV;
$CHAINOPT    = join(" ",@ARGV);

# --- Option bitmask ----------------------------------------------
$STDOPT = ($ALLOPT &  3) >> 0; # i.e.    011, on 2 bits for future extensions
$OPTOPT = ($ALLOPT &  4) >> 2; # i.e.    100
$COMPRS = ($ALLOPT & 24) >> 3; # i.e.  11000



# --- ENV variables we may use       ------------------------------
#
# Take this as well for later use.
#$MYSELF= $ENV{"CRS_JOB_FILE"};
$JOB_ID= $ENV{"CRS_JOB_ID"};
$PWD   = $ENV{"PWD"};


# --- Grab STDOUT/STDERR by force (control was stolen from us) ----
# We will restore to reading the real chosen one later ...
$ISTDOUT= $ENV{"STD_OUT"};
$ISTDERR= $ENV{"STD_ERR"};
$STDOUT = basename($ISTDOUT);
$STDERR = basename($ISTDERR);


if( $STDOPT == 1){
    # Option 1 is to redirect to local file
    # after stealing the STD channels.
    if( defined($ISTDOUT) && defined($ISTDERR) ){
	print "$PRGM :: Info: delayed IO mode.\n";
	&STDtrap(0,$STDOUT,$STDERR);
    } else {
	print "$PRGM :: Warning: delayed IO requested but missing ENV\n";
	print "$PRGM :: Info: Reverting to direct IO\n";
    }
} else {
    # Default is to leave as-is
    print "$PRGM :: Info: direct IO mode.\n";
}
#print "$PRGM :: debug : $STDOPT $ISTDOUT $STDOUT $ISTDERR $STDERR\n";



# --- Parse inputs and options ------------------------------------
#
# The CRS software sets up environment variables
# according to the job description file. If a file
# is of type HPSS, the ACTUAL_XXX would refer to
# the file as restored on local disk while the XXX
# would refer to the initial file name (as per in HPSS)
#
for($i =0 ; ; $i++){
    eval('$in = $ENV{"ACTUAL_INPUT$i"}');
    if( ! defined($in) ){ last;}
    eval('$cin = $ENV{"INPUT$i"}');
    if( ! defined($cin) ){ last;}
    push(@CINPUTS,$cin);
    push(@INPUTS,$in);
}


# The first one is used as our input stream, the rest are
# subject to chain options.
# If something else needs to be done for the other input files
# (like adding to the chain option), please, add code with backward
# compatibility possibility. I think this code is suitable for pp
# gstar options modulo this implementation.
$INPUTFILE  = shift @INPUTS;
$CINPUTFILE = shift @CINPUTS;





#
# Other input files may be options.
# - If an input file contains the string StarDb, calibration
#   directory is soft linked to the current directory.
# - If the file name contains StarDb and its name is
#   one of the above pattern. In both case, the file
#   is assumed to contain the chain option.
#
#   Pre* : calibration is processed, run goes after.
#   Opt* : calibration pass is done, then we leave.
#
$copt = "";
$cdir = "";
foreach $file (@CINPUTS){
    if( $file =~ /StarDb/){
	# Calibration run enabled. Create soft link.
	$copt = basename($file);
	$cdir = dirname($file);
	symlink($cdir,"StarDb");
	# make default option "" unless the pattern
	# matches what is in the help list above.
	if($copt !~ m/Pre/ && $copt !~ m/Opt/){ $copt = "";}
    }
}




# --- Parse outputs -----------------------------------------------
#
# The number of output files is unknown but we can evaluate
# this. This loop may also be used for
for($i =0 ; ; $i++){
    eval('$cout  = $ENV{"OUTPUT$i"}');
    if( ! defined($cout)  ){ last;}
    eval('$out = $ENV{"ACTUAL_OUTPUT$i"}');
    if( ! defined($out) ){ last;}
    push(@COUTPUTS,$cout);
    push(@OUTPUTS,$out);
    # Well, some jobs have it created at startup, some don't
    # causing a final staging failure. Therefore, do not trust
    # the CRS pre-job and do it ourselves.
    if( $cout =~ m/HPSS/){
	$tmp = basename($out);
	if( ! -e $tmp){
	    print "$PRGM :: $cout -> $tmp missing\n";
	    symlink($cout,$tmp);
	}
    }
}







# --- Fix default values, check sanity ----------------------------
#
# num events default value
if( $NUMEVT <= 0){ $NUMEVT = 10000;}
# Simplify library version change (commodity)
if($LIBRARY =~ m/dev/i || $LIBRARY =~ m/new/i ||
   $LIBRARY =~ m/pro/i || $LIBRARY =~ m/old/i){
    $CHVER = "star".lc($LIBRARY);
} elsif ($LIBRARY =~ m/cal/i){
    # Special calibration area where tests would be run
    # before code gets commited. 
    $CHVER  = "stardev\n";
    $CHVER .= "ln -s \$STAR_PATH/cal/.\@sys ./.\$STAR_SYS";
    $LIBRARY= "dev (cal)";
} else {
    $CHVER = "starver $LIBRARY";
}
if($INPUTFILE eq ""){
    print STDERR "$PRGM :: Error: no input file specified\n";
    exit;
} else {
    # Extension check. Out chain requires a .daq extension.
    $ext = $CINPUTFILE;
    $ext =~ s/.*\.//g;
    #print "Debug:: [$ext]\n";
    if($ext eq "" || $ext eq $CINPUTFILE){
	# An HPSS file was restored. We need to create
	# a symlink with a .daq name and use this as
	# our input.
	$tmp = basename($INPUTFILE);
	symlink($CINPUTFILE,$tmp);
	$CINPUTFILE = $tmp;
    }
}

# Feature test
$GZIP = "";
if ($COMPRS){
    foreach $file ( ("/bin/gzip","/usr/bin/gzip","/usr/local/bin/gzip") ){
	if( -x $file){ 
	    $GZIP = $file; 
	    last;
	}
    }
    if($GZIP eq ""){
	print STDERR "$PRGM :: Warning: Compress cannot be done. ".
	    " Missing gzip program.\n";
	$COMPRS = 0;
    }
}

$CPUSPD = "unkown";
if( -r "/proc/cpuinfo"){
    open(FI,"/proc/cpuinfo");
    while( defined($line = <FI>) ){
	if($line =~ m/(cpu MHz.*:)(.*)/){
	    $CPUSPD = $2;
	    $CPUSPD =~ s/^\s*(.*?)\s*$/$1/;
	    last;
	}
    }
    close(FI);
}





# --- Display information -----------------------------------------
#
print "Job is starting on               ".localtime()."\n";
print "We are running on                ".hostname()."\n";
print "CPU speed                        $CPUSPD MHz\n";
print "Our job ID is                    $JOB_ID\n";
print "Our working directory            $PWD\n";
print "We will run from library version $LIBRARY\n";
print "Main processing chain options    $CHAINOPT\n"    if($copt !~ m/Opt/);
print "Calibration pass using           $cdir/$copt\n"  if($copt ne "" );
print "The output destination will be   $DESTINATION\n";
print "The number of events would be    $NUMEVT\n";
print "The chain will run over file     $INPUTFILE\n";
print "This file is stored as           $CINPUTFILE\n";
print "Outputs initial will be          ".join(" ",@COUTPUTS)."\n";
print "Outputs final will be            ".join(" ",@OUTPUTS)."\n";
print "Running condition                ".($OPTOPT?"Optimized":"Non-Optimized")."\n";


if ($COMPRS){ 
    print "Output Compression was required, will use $GZIP\n";
}








# --- Create script, run, check outputs, move to target  ----------
#
# Now, we are ready to go ... What we will do is to create
# a local csh file containing all of the required commands
# and loading. Peffered shell will be csh (available on ALL
# flavor of Unix) rather than tcsh which needs to be installed.
if ( ! open(FO,">$PWD/$JOB_ID.csh") ){
    print STDERR "$PRGM :: Failure to open a temporary file $!\n";
} else {

    # Note that we will be able to dup STDOUT STDERR to a file later
    # (and if required) as well as writing handler routine to prevent
    # from a crash.
    print FO
	"#!/bin/csh\n",
	"setenv GROUP_DIR /afs/rhic/rhstar/group\n", # default GROUP_DIR
	"source \$GROUP_DIR/star_login.csh\n",       # load basic login env
	"unset noclobber\n";                         # over-write
    print FO
	"setenv NODEBUG yes\n" if($OPTOPT);          # STAR soft specific env
    print FO
	"$CHVER\n",                                  # load chosen library env
	"echo \"$PRGM :: Using \`which root4star\`\"\n";  # some info/debug message



    # Pre-process the calibration run first if necessary
    if($copt ne "" ){
	# the file contains the calibration pass chain options
	chomp($chainopt = `cat $cdir/$copt`);
	print FO
	    "echo \"$PRGM :: Calibration pass is starting on \`date\`\"\n",
	    "echo \"\"\n",
	    "root4star -b -q 'bfc.C(10000,\"$chainopt\",\"$CINPUTFILE\")'\n",
	    "echo \"$PRGM :: Calibration is done on \`date\`\"\n";
    }



    # Also process the regular run but only if calib-only was not requested
    if($copt !~ m/Opt/){
	print FO
	    "echo \"$PRGM :: Reco run is starting on \`date\`\"\n",
	    "echo \"\"\n",
	    "setenv StarEndMakerShell\n",            # Option to outpu memory consumption
	    "root4star -b -q 'bfc.C($NUMEVT,\"$CHAINOPT\",\"$CINPUTFILE\")'\n";
    }
    close(FO);
    chmod(0755,"$PWD/$JOB_ID.csh");





    &List("Our working directory contains","We will now start to run ...");

    $elaps  = time();
    system("$PWD/$JOB_ID.csh");
    $status = $?;
    $elaps  = time() - $elaps;



    # after this, we may have crashed or not
    if($status == 0){
	print "$PRGM :: Info: The chain as completed without failure\n";
    } else {
	print STDERR "$PRGM :: Error: chain stopped with status $status\n";
    }
    &List("The directory content is now ...");





    # But please, do not stop there but move the output if required
    # Required means that the option was HPSS, UNIX option means
    # that it will be written over NFS so we do not need to move the
    # file. We can recognize the difference because the $cfile is
    # different than the $file in HPSS mode and identical in NFS mode.
    for($i=0 ; $i <= $#COUTPUTS ; $i++){
	$cfile = $COUTPUTS[$i];

	if( -e $cfile){
	    $file  = $OUTPUTS[$i];
	    $ffile = "";

	    if( $file ne $cfile){
		# Massage the substitution. This is a HPSS file
		# cloned/copied to a disk as well.
		if( $DESTINATION eq "." || $DESTINATION eq "./"){
		    # will ignore those i.e. save in HPSS only.
		    $ffile = $cfile;
		} else {
		    # do copy by doing path substitution
		    $ffile = $file;
		    $ffile =~ s|$HPSSBASE|$DESTINATION|;
		}
	    } elsif ( dirname($file) eq "."){
		# This is a file left on the local disk we want
		# to move now.
		$ffile = $file;
		$ffile =~ s|./|$DESTINATION/|;
	    } else {
		# Last case is that the directory name is
		# not "." and the file is of type=UNIX. 
		# This means that the description file was 
		# written to do direct-IO for outputstream.
	    }


	    # OK to copy $cfile -> $ffile is defined
	    if( $ffile ne $cfile){
		&FileCopy($cfile,$ffile);
	    } else {
		print "$PRGM :: Info: $file is at its final destination\n";
	    }

	} else {
	    # Oups ! The output file was not found
	    print "$PRGM :: Warning: action did not produce expected $cfile\n";
	}
    }
    print "$PRGM :: Info: All output checked. Done\n";
    if( $CPUSPD ne "unkown"){
	print "$PRGM :: Info: Chain done in $elaps seconds, Time/CPUSpeed= ".($elaps/$CPUSPD)."\n";
    }


    # Take care of STD.
    if($COMPRS){ print "$PRGM :: Will now perform STD Compression\n";}
    if( $STDOPT == 1){
	&STDtrap(2);

	if($COMPRS & 1){ ($STDOUT,$ISTDOUT) = &Compress($STDOUT,$ISTDOUT);}
	&FileCopy($STDOUT,$ISTDOUT);

	if($COMPRS & 2){ ($STDERR,$ISTDERR) = &Compress($STDERR,$ISTDERR);}
	&FileCopy($STDERR,$ISTDERR);
    } else {
	# Same routine handling compression
	&STDtrap(2);
	if($COMPRS & 1){ ($ISTDOUT,$STDOUT) = &Compress($ISTDOUT,$STDOUT);}
	if($COMPRS & 2){ ($ISTDERR,$STDERR) = &Compress($ISTDERR,$STDERR);}
    }
}




# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
# Subroutines
# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
#
# Compress or not file1. Change name and return
# value of file1/file2 if succeded.
#
sub Compress
{
    my($file1,$file2)=@_;

    if($GZIP eq ""){ return ($file1,$file2);}
    if(-e "$file1.gz"){ unlink("$file1.gz");}

    system("$GZIP $file1 ");
    if( -e $file1.".gz"){
	# Change fie names origin -> destination
	$file1 .= ".gz";

	# but also delete first the target file name 
	# if exists before changing its name. Otherwise,
	# will will have a left-over.
	if(-e "$file2"){ unlink("$file2");}
	$file2 .= ".gz";
    }
    ($file1,$file2);
}


#
# Subroutine to check and create path. mkpath()
# in the perl module does not return the failure
# reasons and do not implement special cases as
# we do. So, screw it ...
#
sub MkPath
{
    my($dir,$level)=@_;
    my(@items,$tmp,$el,$i);

    # default
    if( ! defined($level) ){ $level = 0;}

    @items = split("/",$dir);
    shift(@items);               # strip first blank space
    $tmp = "";
    $i   = 0;
    foreach $el (@items){
	$tmp .= "/$el";
	$i++;
	if( ! -d $tmp){
	    #
	    # BTW : In case of a NFS mount failure, this block will
	    # be executed which means that we will go into an infinit
	    # loop until the disk is available.
	    #
	    if (-f $tmp){
		# Oupses !! File exists with same name than directory.
		# This is a no-no in Uglix-land.
		print STDERR
		    "$PRGM :: Error: Cannot create dir $tmp. ",
		    "File exists with the same name.\n";
		return -1;
	    }

	    # we can even test where this fails ...
	    # The level variable is used to prevent from accidental directory creation
	    # in case of disk unmount. For example, level = 2 will prevent creation
	    # before a /star/dataXX directory ...
	    if ($i >= $level){
		if( ! mkdir($tmp,0773) ){
		    print STDERR
			"$PRGM :: Error: Failed to create $tmp [$!]\n";
		    return -2;
		}
	    }
	}
    }
    1;
}


#
# Small common routine for doing a ls/directory
# content (helps for debugging purposes).
#
sub List
{
    my($smess,$emess)=@_;
    my($i);

    for($i=0 ; $i < 45 ; $i++){ print "-=";}
    print "\n";
    print "$PRGM :: Info: $smess\n" if ( defined($smess) );
    print `ls -al`;
    print "$PRGM :: Info: $emess\n" if ( defined($emess) );
    for($i=0 ; $i < 45 ; $i++){ print "-=";}
    print "\n";
}


#
# Routine handling the file copy
#
sub FileCopy
{
    my($flnm,$target)=@_;
    my($tdir);
    my($k);

    $tdir = dirname($target);
    $k    = 0;

  CREATE_DIR:
    # create directory all the way up but also, try multiple times
    # if it fails.
    if( &MkPath($tdir,2) != 1){
	print "$PRGM :: Info: Failed to create $tdir on ".localtime()."\n";
	$k++;
	if($k != $NTRIES){
	    sleep($SLPTIME);
	    goto CREATE_DIR;
	} else {
	    print STDERR "$PRGM :: Error: Failed to create path $tdir\n";
	}
    }

    # if the final file already exists, remove it first
    if( -e $target){ unlink($target);}

    # Informative message
    print "$PRGM :: Info: Copying $flnm -> $target\n";

    # Copy now
    copy($flnm,$target);

    # Double check this
    if( ! -e $target){
	print STDERR "$PRGM :: Warning: Action did not create $target\n";
    }
}



#
# Sub-routine handling STDOUT/STDERR
# 'mode' is as follow
#  0      create
#  1      append/create
#  def    close
#
# All io in auto-flush mode.
#
sub STDtrap
{
    my($mode,$outf,$errf)=@_;

    # Open create or append 
    if ($mode == 0 || $mode == 1){
	# dup and auto-flush
	open(SAVEERR,">&STDERR");
	$mode==0?open(STDERR,">$errf"):open(STDERR,">>$errf");
	select(STDERR); $| = 1;

	open(SAVEOUT,">&STDOUT");
	$mode==0?open(STDOUT,">$outf"):open(STDOUT,">>$outf");
	select(STDOUT); $| = 1;

    } elsif ( $mode == 2){
	# trash STD-IO
	open(STDERR,">&/dev/null");
	open(STDOUT,">&/dev/null");

    } else {
	# default is to close those pipes
	close(STDERR);
	close(STDOUT);
	open(STDERR,">&SAVEERR");
	close(SAVEERR);
	open(STDOUT,">&SAVEOUT");
	close(SAVEOUT);
    }
}
